{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6048b3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling raw data into hourly, daily, and weekly formats...\n",
      "Resampling complete.\n",
      "\n",
      "ðŸš€ STARTING PIPELINE 1: HOURLY MODELS ðŸš€\n",
      "============================================================\n",
      "\n",
      "Building models for 161 unique meters (hourly)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Meters (hourly): 100%|\u001b[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 161/161 [03:02<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully trained and saved 138 models.\n",
      "\n",
      "âœ… HOURLY PIPELINE COMPLETE âœ…\n",
      "\n",
      "\n",
      "ðŸš€ STARTING PIPELINE 2: DAILY MODELS ðŸš€\n",
      "============================================================\n",
      "\n",
      "Building models for 161 unique meters (daily)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Meters (daily): 100%|\u001b[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 161/161 [01:07<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully trained and saved 71 models.\n",
      "\n",
      "âœ… DAILY PIPELINE COMPLETE âœ…\n",
      "\n",
      "\n",
      "ðŸš€ STARTING PIPELINE 3: WEEKLY MODELS ðŸš€\n",
      "============================================================\n",
      "\n",
      "Building models for 161 unique meters (weekly)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Meters (weekly): 100%|\u001b[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 161/161 [00:19<00:00]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully trained and saved 20 models.\n",
      "\n",
      "âœ… WEEKLY PIPELINE COMPLETE âœ…\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    classification_report, \n",
    "    confusion_matrix, \n",
    "    ConfusionMatrixDisplay, \n",
    "    RocCurveDisplay, \n",
    "    roc_auc_score\n",
    ")\n",
    "import joblib\n",
    "import os\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from tqdm import tqdm\n",
    "\n",
    "## ------------------------------------------------------------------------------------------------------------------ ##\n",
    "##                                 DATA PREPARATION                                   ##\n",
    "## ------------------------------------------------------------------------------------------------------------------ ##\n",
    "\n",
    "def resample_data(df_raw):\n",
    "\n",
    "    print(\"Resampling raw data into hourly, daily, and weekly formats...\")\n",
    "    # --- Ensure correct data types and set a datetime index ---\n",
    "    df_raw['LocalTimeCol'] = pd.to_datetime(df_raw['LocalTimeCol'])\n",
    "    df_raw.set_index('LocalTimeCol', inplace=True)\n",
    "\n",
    "    # --- Resample to HOURLY frequency â° ---\n",
    "    df_hourly = df_raw.groupby('MeterCode').resample('h').agg({\n",
    "        'FR': 'mean',  # Use the average flow rate within the hour\n",
    "        'FV': 'mean'    # Use the average flow volume for the hour\n",
    "    }).reset_index()\n",
    "\n",
    "    # --- Resample to DAILY frequency ðŸ—“ï¸ ---\n",
    "    df_daily = df_raw.groupby('MeterCode').resample('D').agg({\n",
    "        'FR': 'mean',  # Use the average flow rate across the day\n",
    "        'FV': 'mean'    # Use the average flow volume for the day\n",
    "    }).reset_index()\n",
    "    \n",
    "    # --- NEW: Resample to WEEKLY frequency ðŸ“… ---\n",
    "    df_weekly = df_raw.groupby('MeterCode').resample('W').agg({\n",
    "        'FR': 'mean',  # Use the average flow rate across the week\n",
    "        'FV': 'mean'    # Use the average flow volume for the week\n",
    "    }).reset_index()\n",
    "    \n",
    "    print(\"Resampling complete.\")\n",
    "    return df_hourly, df_daily, df_weekly\n",
    "\n",
    "def prepare_features(df):\n",
    "\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Ensure LocalTimeCol is in datetime format\n",
    "    df['LocalTimeCol'] = pd.to_datetime(df['LocalTimeCol'])\n",
    "    \n",
    "    # Fill NaN values in core columns with 0\n",
    "    df[[\"FR\", \"FV\"]] = df[[\"FR\", \"FV\"]].fillna(0)\n",
    "    \n",
    "    # Create target variable 'is_idle' using ONLY FR\n",
    "    df = df.sort_values(['MeterCode', 'LocalTimeCol']).reset_index(drop=True)\n",
    "    df['is_idle'] = (df['FR'] <= 0.1).astype(int)\n",
    "\n",
    "    ## --- Feature Engineering ---\n",
    "    # Time-based features\n",
    "    df['hour'] = df['LocalTimeCol'].dt.hour\n",
    "    df['day_of_week'] = df['LocalTimeCol'].dt.dayofweek\n",
    "    df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)\n",
    "    \n",
    "    # Lagged features for FR and FV (these mean different things for hourly vs daily vs weekly)\n",
    "    df['FR_lag1'] = df.groupby('MeterCode')['FR'].shift(1)\n",
    "    df['FV_lag1'] = df.groupby('MeterCode')['FV'].shift(1)\n",
    "    \n",
    "    # Rolling window features for FR and FV\n",
    "    df['FR_roll_mean4'] = df.groupby('MeterCode')['FR'].rolling(window=4, min_periods=1).mean().reset_index(0, drop=True)\n",
    "    df['FV_roll_std4'] = df.groupby('MeterCode')['FV'].rolling(window=4, min_periods=1).std().reset_index(0, drop=True)\n",
    "    \n",
    "    # Fill any remaining NaNs created by new features\n",
    "    df = df.fillna(0)\n",
    "    \n",
    "    return df\n",
    "\n",
    "## ------------------------------------------------------------------------------------------------------------------ ##\n",
    "##                               MODEL BUILDING & TRAINING                                ##\n",
    "## ------------------------------------------------------------------------------------------------------------------ ##\n",
    "\n",
    "def build_rfc_models(df_features, features, granularity_suffix, min_data_points):\n",
    "   \n",
    "    rfc_results = []\n",
    "    \n",
    "    model_dir = f\"../Models/idle_models/idle_meter_rfc_models{granularity_suffix}\"\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    \n",
    "    unique_meters = df_features['MeterCode'].unique()\n",
    "    print(f\"\\nBuilding models for {len(unique_meters)} unique meters ({granularity_suffix.strip('_')})...\")\n",
    "    \n",
    "    successful_models = 0\n",
    "    \n",
    "    progress_bar_desc = f\"Processing Meters ({granularity_suffix.strip('_')})\"\n",
    "    for meter_code in tqdm(unique_meters, desc=progress_bar_desc, colour='green',\n",
    "                           bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]'):\n",
    "        \n",
    "        meter_data = df_features[df_features['MeterCode'] == meter_code].copy()\n",
    "        \n",
    "        if len(meter_data) < min_data_points:\n",
    "            continue\n",
    "            \n",
    "        y = meter_data['is_idle']\n",
    "        if y.nunique() < 2:\n",
    "            continue\n",
    "            \n",
    "        X = meter_data[features]\n",
    "        \n",
    "        try:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, y, test_size=0.2, random_state=42, stratify=y\n",
    "            )\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "        min_samples = y_train.value_counts().min()\n",
    "        if min_samples < 2:\n",
    "            continue\n",
    "\n",
    "        k = min(5, min_samples - 1)\n",
    "        smote = SMOTE(random_state=42, k_neighbors=k)\n",
    "        X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train_smote)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        model = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
    "        model.fit(X_train_scaled, y_train_smote)\n",
    "        \n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        \n",
    "        # Define all possible labels for this classification problem\n",
    "        all_labels = [0, 1]\n",
    "\n",
    "        rfc_results.append({\n",
    "            \"MeterCode\": meter_code, \"Model\": model, \"Scaler\": scaler,\n",
    "            \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "            \n",
    "            # --- MODIFIED: Add the 'labels' parameter ---\n",
    "            \"Classification_Report\": classification_report(y_test, y_pred, labels=all_labels, output_dict=True, zero_division=0),\n",
    "            \n",
    "            # --- MODIFIED: Add the 'labels' parameter ---\n",
    "            \"Confusion_Matrix\": confusion_matrix(y_test, y_pred, labels=all_labels),\n",
    "            \n",
    "            \"X_test\": X_test_scaled, \"y_test\": y_test,\n",
    "        })\n",
    "        \n",
    "        meter_model_path = os.path.join(model_dir, f\"{meter_code}{granularity_suffix}_model.joblib\")\n",
    "        meter_scaler_path = os.path.join(model_dir, f\"{meter_code}{granularity_suffix}_scaler.joblib\")\n",
    "        \n",
    "        joblib.dump(model, meter_model_path)\n",
    "        joblib.dump(scaler, meter_scaler_path)\n",
    "        \n",
    "        successful_models += 1\n",
    "\n",
    "    print(f\"Successfully trained and saved {successful_models} models.\")\n",
    "    return rfc_results\n",
    "\n",
    "## ------------------------------------------------------------------------------------------------------------------ ##\n",
    "##                                        RESULTS & REPORTING                                         ##\n",
    "## ------------------------------------------------------------------------------------------------------------------ ##\n",
    "\n",
    "def save_results_to_csv(results_list, model_type_name):\n",
    "\n",
    "    if not results_list: return\n",
    "    output_dir = \"../Output/idle_prediction/comparison_results\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    summary_data = [{\"MeterCode\": r[\"MeterCode\"], \"Model_Type\": model_type_name, \"Accuracy\": r[\"Accuracy\"],\n",
    "                     \"Classification_Report\": str(r[\"Classification_Report\"])} for r in results_list]\n",
    "                     \n",
    "    csv_path = os.path.join(output_dir, f\"{model_type_name}_results.csv\")\n",
    "    pd.DataFrame(summary_data).to_csv(csv_path, index=False)\n",
    "    # print(f\"CSV results saved to {csv_path}\")\n",
    "\n",
    "## ------------------------------------------------------------------------------------------------------------------ ##\n",
    "##                                 MAIN EXECUTION                                   ##\n",
    "## ------------------------------------------------------------------------------------------------------------------ ##\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # --- Load and Resample Data ---\n",
    "    try:\n",
    "        df_raw = pd.read_csv(\"../../Data/Data1.csv\")\n",
    "        df_raw.columns = ['Id', 'LocalTimeCol', 'MeterCode', 'FR', 'FV', 'Today', 'NetTotal', 'created_by', 'creation_date', 'modified_date']\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: Data file not found. Make sure the path '../../Data/Data1.csv' is correct.\")\n",
    "        exit()\n",
    "        \n",
    "    # MODIFIED: Unpack the new weekly dataframe\n",
    "    df_hourly, df_daily, df_weekly = resample_data(df_raw.copy())\n",
    "    \n",
    "    # Define the common feature set\n",
    "    features = ['FR', 'FV', 'hour', 'day_of_week', 'is_weekend', 'FR_lag1', 'FV_lag1', 'FR_roll_mean4', 'FV_roll_std4']\n",
    "    \n",
    "    # --- PIPELINE 1: HOURLY MODELS ---\n",
    "    print(\"\\nðŸš€ STARTING PIPELINE 1: HOURLY MODELS ðŸš€\")\n",
    "    print(\"=\" * 60)\n",
    "    df_hourly_features = prepare_features(df_hourly)\n",
    "    results_hourly = build_rfc_models(df_hourly_features, features, granularity_suffix='_hourly', min_data_points=100)\n",
    "    if results_hourly:\n",
    "        # save_results_to_pdf(results_hourly, report_name=\"hourly_model_results.pdf\")\n",
    "        save_results_to_csv(results_hourly, \"RandomForest_Hourly\")\n",
    "    print(\"\\nâœ… HOURLY PIPELINE COMPLETE âœ…\\n\")\n",
    "\n",
    "    # --- PIPELINE 2: DAILY MODELS ---\n",
    "    print(\"\\nðŸš€ STARTING PIPELINE 2: DAILY MODELS ðŸš€\")\n",
    "    print(\"=\" * 60)\n",
    "    df_daily_features = prepare_features(df_daily)\n",
    "    results_daily = build_rfc_models(df_daily_features, features, granularity_suffix='_daily', min_data_points=20)\n",
    "    if results_daily:\n",
    "        # save_results_to_pdf(results_daily, report_name=\"daily_model_results.pdf\")\n",
    "        save_results_to_csv(results_daily, \"RandomForest_Daily\")\n",
    "    print(\"\\nâœ… DAILY PIPELINE COMPLETE âœ…\\n\")\n",
    "\n",
    "    # --- NEW: PIPELINE 3: WEEKLY MODELS ---\n",
    "    print(\"\\nðŸš€ STARTING PIPELINE 3: WEEKLY MODELS ðŸš€\")\n",
    "    print(\"=\" * 60)\n",
    "    df_weekly_features = prepare_features(df_weekly)\n",
    "    results_weekly = build_rfc_models(df_weekly_features, features, granularity_suffix='_weekly', min_data_points=5)\n",
    "    if results_weekly:\n",
    "        # save_results_to_pdf(results_weekly, report_name=\"weekly_model_results.pdf\")\n",
    "        save_results_to_csv(results_weekly, \"RandomForest_Weekly\")\n",
    "    print(\"\\nâœ… WEEKLY PIPELINE COMPLETE âœ…\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2917d5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcdb9afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸš€ STARTING PIPELINE 2: 15 MIN MODELS ðŸš€\n",
      "============================================================\n",
      "--- Building Models using random forest classifier for all Meters ---\n",
      "------------------------------------------------------------\n",
      "Building models for 161 unique meters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Meters: 100%|\u001b[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 161/161 [03:31<00:00]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Summary ---\n",
      "Total unique meters processed: 161\n",
      "Successfully trained and saved models: 138\n",
      "Results stored for 138 models\n",
      "\n",
      "--- Saving Reports ---\n",
      "------------------------------------------------------------\n",
      "Comparison results saved to ../Output/idle_prediction/comparison_results\\RandomForestClassifier_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## 15min idle state prediction using RandomForestClassifier (target column using Fr only )\n",
    "## ------------------------------------------------------------------------------------------------------------------ ##\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    classification_report, \n",
    "    confusion_matrix, \n",
    "    ConfusionMatrixDisplay, \n",
    "    RocCurveDisplay, \n",
    "    roc_auc_score\n",
    ")\n",
    "import joblib\n",
    "import os\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from tqdm import tqdm\n",
    "\n",
    "def prepare_features_for_analysis(df):\n",
    "   \n",
    "    df = df.copy()\n",
    "    \n",
    "    # Ensure LocalTimeCol is in datetime format\n",
    "    df['LocalTimeCol'] = pd.to_datetime(df['LocalTimeCol'])\n",
    "    \n",
    "    # Fill NaN values in core columns with 0\n",
    "    df[[\"FR\", \"FV\"]] = df[[\"FR\", \"FV\"]].fillna(0)\n",
    "    \n",
    "    # Create target variable 'is_idle' using ONLY FR\n",
    "    df = df.sort_values(['MeterCode', 'LocalTimeCol']).reset_index(drop=True)\n",
    "    df['is_idle'] = (df['FR'] <= 0.1).astype(int)\n",
    "\n",
    "    ## --- Feature Engineering ---\n",
    "    # Time-based features\n",
    "    df['hour'] = df['LocalTimeCol'].dt.hour\n",
    "    df['day_of_week'] = df['LocalTimeCol'].dt.dayofweek\n",
    "    df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)\n",
    "    \n",
    "    # Lagged features for FR and FV (these mean different things for hourly vs daily)\n",
    "    df['FR_lag1'] = df.groupby('MeterCode')['FR'].shift(1)\n",
    "    df['FV_lag1'] = df.groupby('MeterCode')['FV'].shift(1)\n",
    "    \n",
    "    # Rolling window features for FR and FV\n",
    "    df['FR_roll_mean4'] = df.groupby('MeterCode')['FR'].rolling(window=4, min_periods=1).mean().reset_index(0, drop=True)\n",
    "    df['FV_roll_std4'] = df.groupby('MeterCode')['FV'].rolling(window=4, min_periods=1).std().reset_index(0, drop=True)\n",
    "    \n",
    "    # Fill any remaining NaNs created by new features\n",
    "    df = df.fillna(0)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def build_rfc_models(df_features, features):\n",
    "\n",
    "    rfc_results = []\n",
    "    \n",
    "    model_dir = \"../Models/idle_models/idle_meter_15min_models\"\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    \n",
    "    unique_meters = df_features['MeterCode'].unique()\n",
    "    print(f\"Building models for {len(unique_meters)} unique meters...\")\n",
    "    \n",
    "    successful_models = 0\n",
    "    \n",
    "    for meter_code in tqdm(unique_meters, desc=\"Processing Meters\", colour='green',\n",
    "                           bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]'):\n",
    "        \n",
    "        meter_data = df_features[df_features['MeterCode'] == meter_code].copy()\n",
    "        \n",
    "        if len(meter_data) < 100:\n",
    "            continue\n",
    "            \n",
    "        y = meter_data['is_idle']\n",
    "        if y.nunique() < 2:\n",
    "            continue\n",
    "            \n",
    "        X = meter_data[features]\n",
    "        \n",
    "        try:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, y, test_size=0.2, random_state=42, stratify=y\n",
    "            )\n",
    "        except ValueError as e:\n",
    "            continue\n",
    "\n",
    "        smote = SMOTE(random_state=42)\n",
    "        X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train_smote)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        model = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
    "        model.fit(X_train_scaled, y_train_smote)\n",
    "        \n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "        rfc_results.append({\n",
    "            \"Model_name\": f\"RandomForest_{meter_code}\",\n",
    "            \"MeterCode\": meter_code,\n",
    "            \"Model\": model,\n",
    "            \"Scaler\": scaler,\n",
    "            \"Accuracy\": accuracy,\n",
    "            \"Classification_Report\": report,\n",
    "            \"Confusion_Matrix\": cm,\n",
    "            \"X_test\": X_test_scaled,\n",
    "            \"y_test\": y_test,\n",
    "            \"y_pred\": y_pred,\n",
    "            \"Training_samples\": len(X_train),\n",
    "            \"Test_samples\": len(X_test),\n",
    "            \"Features_used\": features\n",
    "        })\n",
    "        \n",
    "        meter_model_path = os.path.join(model_dir, f\"{meter_code}_model.joblib\")\n",
    "        meter_scaler_path = os.path.join(model_dir, f\"{meter_code}_scaler.joblib\")\n",
    "        \n",
    "        joblib.dump(model, meter_model_path)\n",
    "        joblib.dump(scaler, meter_scaler_path)\n",
    "        \n",
    "        successful_models += 1\n",
    "\n",
    "    print(f\"\\n--- Summary ---\")\n",
    "    print(f\"Total unique meters processed: {len(unique_meters)}\")\n",
    "    print(f\"Successfully trained and saved models: {successful_models}\")\n",
    "    print(f\"Results stored for {len(rfc_results)} models\")\n",
    "    \n",
    "    return rfc_results\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def save_results_to_csv(results_list, model_type_name, output_dir=\"../Output/idle_prediction/comparison_results\"):\n",
    "\n",
    "    if not results_list:\n",
    "        print(f\"No results to save for {model_type_name}.\")\n",
    "        return\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    summary_data = []\n",
    "    for result in results_list:\n",
    "        report = result[\"Classification_Report\"]\n",
    "        summary_data.append({\n",
    "            \"MeterCode\": result[\"MeterCode\"],\n",
    "            \"Model_Type\": model_type_name,\n",
    "            \"Accuracy\": result[\"Accuracy\"],\n",
    "            \"Classification_Report\": str(report) \n",
    "        })\n",
    "        \n",
    "    df_summary = pd.DataFrame(summary_data)\n",
    "    \n",
    "    csv_path = os.path.join(output_dir, f\"{model_type_name}_results.csv\")\n",
    "    df_summary.to_csv(csv_path, index=False)\n",
    "    print(f\"Comparison results saved to {csv_path}\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Load the dataset\n",
    "    try:\n",
    "        df = pd.read_csv(\"../../Data/3mon.csv\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: Data file not found. Make sure the path '../../Data/3mon.csv' is correct.\")\n",
    "        exit()\n",
    "        \n",
    "    df.columns = ['Id', 'LocalTimeCol', 'MeterCode', 'FR', 'FV', 'Today', 'NetTotal', 'created_by', 'creation_date', 'modified_date']\n",
    "    \n",
    "    print(\"\\nðŸš€ STARTING PIPELINE 2: 15 MIN MODELS ðŸš€\")\n",
    "    print(\"=\" * 60)\n",
    "    # Pre-process and prepare features (this now creates the new columns)\n",
    "    df_features = prepare_features_for_analysis(df)\n",
    "    \n",
    "    # Define the common feature set\n",
    "    features = ['FR', 'FV', 'hour', 'day_of_week', 'is_weekend', 'FR_lag1', 'FV_lag1', 'FR_roll_mean4', 'FV_roll_std4']\n",
    "\n",
    "    # Build and save individual models for each meter\n",
    "    print(\"--- Building Models using random forest classifier for all Meters ---\")\n",
    "    print(\"-\" * 60)\n",
    "    rfc_results = build_rfc_models(df_features, features)\n",
    "    \n",
    "    # Save results\n",
    "    if rfc_results:\n",
    "        print(\"\\n--- Saving Reports ---\")\n",
    "        print(\"-\" * 60)\n",
    "        save_results_to_csv(rfc_results, \"RandomForestClassifier\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
